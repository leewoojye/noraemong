# transcribe_and_sync.py

import time
import json
import os
from pathlib import Path
import argparse
from typing import List, Dict, Optional, Tuple
import difflib
import re
from dataclasses import dataclass
import unicodedata

# Audio processing and speech recognition
from faster_whisper import WhisperModel

# Text processing for lyrics alignment
try:
    from fuzzywuzzy import fuzz, process
except ImportError:
    print("âš ï¸  fuzzywuzzy not installed. Installing...")
    os.system("pip install fuzzywuzzy python-levenshtein")
    from fuzzywuzzy import fuzz, process

@dataclass
class LyricSegment:
    """Represents a synchronized lyric segment with timing information."""
    start_time: float
    end_time: float
    text: str
    confidence: float = 0.0
    word_timings: Optional[List[Dict]] = None

def format_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹(HH:MM:SS,ms)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    milliseconds = round(seconds * 1000.0)
    hours = milliseconds // 3_600_000
    milliseconds %= 3_600_000
    minutes = milliseconds // 60_000
    milliseconds %= 60_000
    seconds = milliseconds // 1_000
    milliseconds %= 1_000
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

def save_as_srt(segments: List[LyricSegment], output_path: Path):
    """ì¶”ì¶œëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ .srt ìë§‰ íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_path, 'w', encoding='utf-8') as srt_file:
        for i, segment in enumerate(segments):
            start = format_time(segment.start_time)
            end = format_time(segment.end_time)
            text = segment.text.strip()
            
            srt_file.write(f"{i + 1}\n")
            srt_file.write(f"{start} --> {end}\n")
            srt_file.write(f"{text}\n\n")
    print(f"ğŸ¬ SRT ìë§‰ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

def save_as_txt(segments: List[LyricSegment], output_path: Path):
    """ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ .txt íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_path, 'w', encoding='utf-8') as txt_file:
        for segment in segments:
            txt_file.write(segment.text.strip() + "\n")
    print(f"ğŸ“„ ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

def save_as_lrc(segments: List[LyricSegment], output_path: Path):
    """ì¶”ì¶œëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ .lrc ê°€ì‚¬ íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_path, 'w', encoding='utf-8') as lrc_file:
        lrc_file.write("[ar:Generated by AI Transcription]\n")
        lrc_file.write("[ti:Synchronized Lyrics]\n")
        lrc_file.write("[by:AI Lyrics Sync]\n\n")
        
        for segment in segments:
            minutes = int(segment.start_time // 60)
            seconds = segment.start_time % 60
            timestamp = f"[{minutes:02d}:{seconds:05.2f}]"
            lrc_file.write(f"{timestamp}{segment.text}\n")
    print(f"ğŸµ LRC ê°€ì‚¬ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

def save_as_json(segments: List[LyricSegment], output_path: Path):
    """ì¶”ì¶œëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„¸í•œ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    data = {
        "metadata": {
            "generator": "AI Transcription & Sync",
            "version": "1.0",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_segments": len(segments)
        },
        "segments": []
    }
    
    for segment in segments:
        segment_data = {
            "start_time": segment.start_time,
            "end_time": segment.end_time,
            "duration": segment.end_time - segment.start_time,
            "text": segment.text,
            "confidence": segment.confidence
        }
        
        if segment.word_timings:
            segment_data["word_timings"] = segment.word_timings
        
        data["segments"].append(segment_data)
    
    with open(output_path, 'w', encoding='utf-8') as json_file:
        json.dump(data, json_file, indent=2, ensure_ascii=False)
    print(f"ğŸ“Š JSON ë°ì´í„° íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

class LyricsProcessor:
    """ê°€ì‚¬/í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ë° ì •ê·œí™”ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤."""
    
    def load_lyrics_file(self, file_path: str) -> List[str]:
        """ë‹¤ì–‘í•œ í˜•ì‹ì˜ ê°€ì‚¬ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"ê°€ì‚¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if file_path.suffix.lower() == '.lrc':
            return self._parse_lrc_text(content)
        elif file_path.suffix.lower() == '.srt':
            return self._parse_srt_text(content)
        else:
            return self._parse_plain_text(content)
    
    def _parse_plain_text(self, content: str) -> List[str]:
        """ì¼ë°˜ í…ìŠ¤íŠ¸ ê°€ì‚¬ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        lines = content.split('\n')
        lyrics = [line.strip() for line in lines if line.strip()]
        return lyrics
    
    def _parse_lrc_text(self, content: str) -> List[str]:
        """LRC í˜•ì‹ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        lines = content.split('\n')
        lyrics = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # LRC íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ [mm:ss.xx] ì œê±°
            text = re.sub(r'\[\d+:\d+\.\d+\]', '', line).strip()
            if text:
                lyrics.append(text)
                
        return lyrics
    
    def _parse_srt_text(self, content: str) -> List[str]:
        """SRT í˜•ì‹ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        lines = content.split('\n')
        lyrics = []
        
        for line in lines:
            line = line.strip()
            # ì‹œí€€ìŠ¤ ë²ˆí˜¸, íƒ€ì„ìŠ¤íƒ¬í”„, ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
            if (not line or 
                line.isdigit() or 
                '-->' in line):
                continue
            lyrics.append(line)
            
        return lyrics
    
    def normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ë§¤ì¹­ì„ ìœ„í•œ ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        text = text.lower()
        text = ' '.join(text.split())
        text = re.sub(r'[^\w\s]', ' ', text)
        text = ' '.join(text.split())
        text = unicodedata.normalize('NFKD', text)
        return text

class AudioTranscriber:
    """ì˜¤ë””ì˜¤ ì „ì‚¬ ë° ê°€ì‚¬ ë™ê¸°í™”ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    
    def __init__(self, model_size: str = "base", device: str = "auto"):
        self.model_size = model_size
        self.device = device
        self.model = None
        self.lyrics_processor = LyricsProcessor()
        self._load_model()
    
    def _load_model(self):
        """Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print(f"ğŸ“¥ Whisper ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_size}")
        try:
            self.model = WhisperModel(self.model_size, device=self.device)
            print("âœ… Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def transcribe_with_timestamps(self, audio_path: str, language: Optional[str] = None) -> List[LyricSegment]:
        """ì˜¤ë””ì˜¤ë¥¼ ì „ì‚¬í•˜ê³  íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ LyricSegmentë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        print(f"ğŸ¤ ì˜¤ë””ì˜¤ ì „ì‚¬ ì¤‘: {Path(audio_path).name}")
        
        try:
            segments, info = self.model.transcribe(
                audio_path,
                beam_size=5,
                word_timestamps=True,
                language=language
            )
            
            segment_list = []
            for segment in segments:
                word_timings = []
                if hasattr(segment, 'words') and segment.words:
                    for word in segment.words:
                        word_data = {
                            'word': word.word.strip(),
                            'start': word.start,
                            'end': word.end,
                            'probability': getattr(word, 'probability', 0.0)
                        }
                        word_timings.append(word_data)
                
                lyric_segment = LyricSegment(
                    start_time=segment.start,
                    end_time=segment.end,
                    text=segment.text.strip(),
                    confidence=1.0,  # ì „ì‚¬ëœ í…ìŠ¤íŠ¸ëŠ” ë†’ì€ ì‹ ë¢°ë„
                    word_timings=word_timings if word_timings else None
                )
                segment_list.append(lyric_segment)
            
            print(f"âœ… ì „ì‚¬ ì™„ë£Œ: {len(segment_list)} ì„¸ê·¸ë¨¼íŠ¸")
            print(f"ğŸŒ ê°ì§€ëœ ì–¸ì–´: {info.language} (í™•ë¥ : {info.language_probability:.2f})")
            
            return segment_list
            
        except Exception as e:
            print(f"âŒ ì „ì‚¬ ì‹¤íŒ¨: {e}")
            raise
    
    def align_lyrics_with_audio(self, audio_path: str, lyrics_path: str, 
                               language: Optional[str] = None,
                               similarity_threshold: float = 0.6) -> List[LyricSegment]:
        """ê¸°ì¡´ ê°€ì‚¬ë¥¼ ì˜¤ë””ì˜¤ì™€ ë™ê¸°í™”í•©ë‹ˆë‹¤."""
        print("ğŸµ ê°€ì‚¬ ë™ê¸°í™” ì‹œì‘...")
        
        # 1ë‹¨ê³„: ê°€ì‚¬ ë¡œë“œ
        print("ğŸ“– ê°€ì‚¬ ë¡œë”© ì¤‘...")
        lyrics_lines = self.lyrics_processor.load_lyrics_file(lyrics_path)
        print(f"âœ… {len(lyrics_lines)}ì¤„ì˜ ê°€ì‚¬ ë¡œë“œ ì™„ë£Œ")
        
        # 2ë‹¨ê³„: ì˜¤ë””ì˜¤ ì „ì‚¬
        print("ğŸ¤ ì˜¤ë””ì˜¤ ì „ì‚¬ ì¤‘...")
        transcription_segments = self._transcribe_for_alignment(audio_path, language)
        
        # 3ë‹¨ê³„: ê°€ì‚¬ì™€ ì „ì‚¬ í…ìŠ¤íŠ¸ ì •ë ¬
        print("ğŸ”„ ê°€ì‚¬ì™€ ì˜¤ë””ì˜¤ ì •ë ¬ ì¤‘...")
        aligned_segments = self._align_text_with_timestamps(
            lyrics_lines, transcription_segments, similarity_threshold
        )
        
        print(f"âœ… ë™ê¸°í™” ì™„ë£Œ: {len(aligned_segments)} ì„¸ê·¸ë¨¼íŠ¸ ì •ë ¬ë¨")
        return aligned_segments
    
    def _transcribe_for_alignment(self, audio_path: str, language: Optional[str] = None) -> List[Dict]:
        """ì •ë ¬ì„ ìœ„í•œ ì˜¤ë””ì˜¤ ì „ì‚¬ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜)"""
        segments, info = self.model.transcribe(
            audio_path,
            beam_size=5,
            word_timestamps=True,
            language=language
        )
        
        segment_list = []
        for segment in segments:
            segment_data = {
                'start': segment.start,
                'end': segment.end,
                'text': segment.text.strip(),
                'words': []
            }
            
            if hasattr(segment, 'words') and segment.words:
                for word in segment.words:
                    word_data = {
                        'word': word.word.strip(),
                        'start': word.start,
                        'end': word.end,
                        'probability': getattr(word, 'probability', 0.0)
                    }
                    segment_data['words'].append(word_data)
            
            segment_list.append(segment_data)
        
        return segment_list
    
    def _align_text_with_timestamps(self, lyrics_lines: List[str], 
                                   transcription_segments: List[Dict],
                                   similarity_threshold: float) -> List[LyricSegment]:
        """ê°€ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ì „ì‚¬ íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ì •ë ¬í•©ë‹ˆë‹¤."""
        aligned_segments = []
        normalized_lyrics = [
            self.lyrics_processor.normalize_text(line) for line in lyrics_lines
        ]
        
        used_segments = set()
        
        for i, (original_lyric, normalized_lyric) in enumerate(zip(lyrics_lines, normalized_lyrics)):
            best_match = None
            best_score = 0
            best_segment_indices = []
            
            # ìµœì  ë§¤ì¹­ ì„¸ê·¸ë¨¼íŠ¸ ì°¾ê¸°
            for j, segment in enumerate(transcription_segments):
                if j in used_segments:
                    continue
                    
                normalized_segment = self.lyrics_processor.normalize_text(segment['text'])
                
                # ìœ ì‚¬ë„ ê³„ì‚°
                similarity_ratio = fuzz.ratio(normalized_lyric, normalized_segment) / 100.0
                partial_ratio = fuzz.partial_ratio(normalized_lyric, normalized_segment) / 100.0
                token_ratio = fuzz.token_sort_ratio(normalized_lyric, normalized_segment) / 100.0
                
                score = max(similarity_ratio, partial_ratio, token_ratio)
                
                if score > best_score and score >= similarity_threshold:
                    best_score = score
                    best_match = segment
                    best_segment_indices = [j]
            
            # ë‹¨ì¼ ë§¤ì¹˜ê°€ ì—†ìœ¼ë©´ ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ ì¡°í•© ì‹œë„
            if best_score < similarity_threshold:
                best_match, best_score, best_segment_indices = self._find_multi_segment_match(
                    normalized_lyric, transcription_segments, used_segments, similarity_threshold
                )
            
            # ì •ë ¬ëœ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
            if best_match and best_score >= similarity_threshold:
                for idx in best_segment_indices:
                    used_segments.add(idx)
                
                if isinstance(best_match, list):
                    start_time = min(seg['start'] for seg in best_match)
                    end_time = max(seg['end'] for seg in best_match)
                    combined_words = []
                    for seg in best_match:
                        combined_words.extend(seg.get('words', []))
                else:
                    start_time = best_match['start']
                    end_time = best_match['end']
                    combined_words = best_match.get('words', [])
                
                aligned_segment = LyricSegment(
                    start_time=start_time,
                    end_time=end_time,
                    text=original_lyric,
                    confidence=best_score,
                    word_timings=combined_words
                )
                aligned_segments.append(aligned_segment)
                
                print(f"âœ“ ë§¤ì¹­ë¨: '{original_lyric[:50]}...' (ì‹ ë¢°ë„: {best_score:.2f})")
            else:
                print(f"âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨: '{original_lyric[:50]}...'")
                # ì¶”ì • íƒ€ì´ë°ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                if aligned_segments:
                    estimated_start = aligned_segments[-1].end_time + 0.5
                    estimated_end = estimated_start + 3.0
                else:
                    estimated_start = 0.0
                    estimated_end = 3.0
                
                aligned_segment = LyricSegment(
                    start_time=estimated_start,
                    end_time=estimated_end,
                    text=original_lyric,
                    confidence=0.0
                )
                aligned_segments.append(aligned_segment)
        
        return aligned_segments
    
    def _find_multi_segment_match(self, target_lyric: str, transcription_segments: List[Dict],
                                 used_segments: set, similarity_threshold: float) -> Tuple[Optional[List[Dict]], float, List[int]]:
        """ì—¬ëŸ¬ ì—°ì† ì „ì‚¬ ì„¸ê·¸ë¨¼íŠ¸ì™€ ê°€ì‚¬ ë¼ì¸ì„ ë§¤ì¹­ ì‹œë„í•©ë‹ˆë‹¤."""
        best_match = None
        best_score = 0
        best_indices = []
        
        for window_size in range(2, 5):
            for start_idx in range(len(transcription_segments) - window_size + 1):
                if any(start_idx + i in used_segments for i in range(window_size)):
                    continue
                
                combined_segments = transcription_segments[start_idx:start_idx + window_size]
                combined_text = " ".join([
                    self.lyrics_processor.normalize_text(seg['text']) 
                    for seg in combined_segments
                ])
                
                similarity_ratio = fuzz.ratio(target_lyric, combined_text) / 100.0
                token_ratio = fuzz.token_sort_ratio(target_lyric, combined_text) / 100.0
                score = max(similarity_ratio, token_ratio)
                
                if score > best_score and score >= similarity_threshold:
                    best_score = score
                    best_match = combined_segments
                    best_indices = list(range(start_idx, start_idx + window_size))
        
        return best_match, best_score, best_indices
    parser = argparse.ArgumentParser(description="faster-whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    parser.add_argument("audio_file", type=str, help="í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model_size", type=str, default="large-v3", help="ì‚¬ìš©í•  Whisper ëª¨ë¸ í¬ê¸° (ì˜ˆ: tiny, base, small, medium, large-v3)")
    parser.add_argument("--device", type=str, default="auto", choices=["auto", "cpu", "cuda"], help="ì‚¬ìš©í•  ì¥ì¹˜ (auto, cpu, cuda)")
    parser.add_argument("--compute_type", type=str, default="default", choices=["default", "int8", "float16"], help="ì—°ì‚° íƒ€ì… (ë©”ëª¨ë¦¬ ë° ì†ë„ ìµœì í™”)")
    parser.add_argument("--language", type=str, default=None, help="ì˜¤ë””ì˜¤ì˜ ì–¸ì–´ ì½”ë“œ (ì˜ˆ: ko, en). ì§€ì • ì‹œ ì–¸ì–´ ê°ì§€ ê³¼ì •ì„ ìƒëµí•˜ì—¬ ë” ë¹ ë¦„.")
    
def transcribe_and_sync():
    """í†µí•©ëœ ì „ì‚¬ ë° ë™ê¸°í™” í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="faster-whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ê°€ì‚¬ì™€ ë™ê¸°í™”í•©ë‹ˆë‹¤.")
    parser.add_argument("audio_file", type=str, help="ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--lyrics_file", type=str, default=None, help="ë™ê¸°í™”í•  ê°€ì‚¬ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)")
    parser.add_argument("--model_size", type=str, default="large-v3", help="ì‚¬ìš©í•  Whisper ëª¨ë¸ í¬ê¸°")
    parser.add_argument("--device", type=str, default="auto", choices=["auto", "cpu", "cuda"], help="ì‚¬ìš©í•  ì¥ì¹˜")
    parser.add_argument("--compute_type", type=str, default="default", choices=["default", "int8", "float16"], help="ì—°ì‚° íƒ€ì…")
    parser.add_argument("--language", type=str, default=None, help="ì˜¤ë””ì˜¤ì˜ ì–¸ì–´ ì½”ë“œ")
    parser.add_argument("--similarity_threshold", type=float, default=0.6, help="í…ìŠ¤íŠ¸ ë§¤ì¹­ì„ ìœ„í•œ ìµœì†Œ ìœ ì‚¬ë„")
    parser.add_argument("--output_dir", type=str, default=None, help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ ê°™ì€ ìœ„ì¹˜)")
    
    args = parser.parse_args()

    audio_path = Path(args.audio_file)
    if not audio_path.exists():
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ -> {audio_path}")
        return

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        output_dir = audio_path.parent
    
    output_dir.mkdir(exist_ok=True)
    output_basename = output_dir / audio_path.stem

    print("="*60)
    if args.lyrics_file:
        print(f"ğŸµ ê°€ì‚¬ ë™ê¸°í™” ëª¨ë“œ: {audio_path.name}")
        print(f"ê°€ì‚¬ íŒŒì¼: {args.lyrics_file}")
    else:
        print(f"ğŸ¤ ì˜¤ë””ì˜¤ ì „ì‚¬ ëª¨ë“œ: {audio_path.name}")
    print(f"ëª¨ë¸: {args.model_size}, ì¥ì¹˜: {args.device}, ì—°ì‚° íƒ€ì…: {args.compute_type}")
    print("="*60)

    try:
        # ì „ì‚¬ê¸° ì´ˆê¸°í™”
        transcriber = AudioTranscriber(
            model_size=args.model_size, 
            device=args.device
        )
        
        start_time = time.perf_counter()
        
        if args.lyrics_file:
            # ê°€ì‚¬ ë™ê¸°í™” ëª¨ë“œ
            if not Path(args.lyrics_file).exists():
                print(f"âŒ ê°€ì‚¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.lyrics_file}")
                return
            
            segments = transcriber.align_lyrics_with_audio(
                str(audio_path), 
                args.lyrics_file,
                language=args.language,
                similarity_threshold=args.similarity_threshold
            )
            
            # ë™ê¸°í™” ê²°ê³¼ ìš”ì•½
            print_sync_summary(segments)
            
        else:
            # ìˆœìˆ˜ ì „ì‚¬ ëª¨ë“œ
            segments = transcriber.transcribe_with_timestamps(
                str(audio_path), 
                language=args.language
            )
        
        end_time = time.perf_counter()
        
        print(f"\nâ±ï¸ ì²˜ë¦¬ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")
        
        # ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥
        save_as_txt(segments, output_basename.with_suffix(".txt"))
        save_as_srt(segments, output_basename.with_suffix(".srt"))
        save_as_lrc(segments, output_basename.with_suffix(".lrc"))
        save_as_json(segments, output_basename.with_suffix(".json"))
        
        print(f"\nğŸ‰ ëª¨ë“  íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_dir}")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def print_sync_summary(segments: List[LyricSegment]):
    """ë™ê¸°í™” ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    total_segments = len(segments)
    high_confidence = sum(1 for seg in segments if seg.confidence >= 0.8)
    medium_confidence = sum(1 for seg in segments if 0.5 <= seg.confidence < 0.8)
    low_confidence = sum(1 for seg in segments if seg.confidence < 0.5)
    
    print(f"\nğŸ“Š ë™ê¸°í™” ê²°ê³¼ ìš”ì•½:")
    print(f"   ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸: {total_segments}")
    print(f"   ë†’ì€ ì‹ ë¢°ë„ (â‰¥80%): {high_confidence}")
    print(f"   ì¤‘ê°„ ì‹ ë¢°ë„ (50-79%): {medium_confidence}")
    print(f"   ë‚®ì€ ì‹ ë¢°ë„ (<50%): {low_confidence}")
    
    if segments:
        total_duration = segments[-1].end_time - segments[0].start_time
        print(f"   ì „ì²´ ê¸¸ì´: {total_duration:.1f}ì´ˆ")
        avg_confidence = sum(seg.confidence for seg in segments) / len(segments)
        print(f"   í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}")

if __name__ == "__main__":
    transcribe_and_sync()