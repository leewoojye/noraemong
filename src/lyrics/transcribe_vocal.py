# transcribe_fast.py

import time
from pathlib import Path
import argparse
from faster_whisper import WhisperModel

def format_time(seconds: float) -> str:
    """ì´ˆë¥¼ SRT íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹(HH:MM:SS,ms)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    milliseconds = round(seconds * 1000.0)
    hours = milliseconds // 3_600_000
    milliseconds %= 3_600_000
    minutes = milliseconds // 60_000
    milliseconds %= 60_000
    seconds = milliseconds // 1_000
    milliseconds %= 1_000
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

def save_as_srt(segments: list, output_path: Path):
    """ì¶”ì¶œëœ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ .srt ìë§‰ íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_path, 'w', encoding='utf-8') as srt_file:
        for i, segment in enumerate(segments):
            start = format_time(segment.start)
            end = format_time(segment.end)
            text = segment.text.strip()
            
            srt_file.write(f"{i + 1}\n")
            srt_file.write(f"{start} --> {end}\n")
            srt_file.write(f"{text}\n\n")
    print(f"ğŸ¬ SRT ìë§‰ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

def save_as_txt(segments: list, output_path: Path):
    """ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ .txt íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(output_path, 'w', encoding='utf-8') as txt_file:
        for segment in segments:
            txt_file.write(segment.text.strip() + "\n")
    print(f"ğŸ“„ ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")

def transcribe_vocal():
    parser = argparse.ArgumentParser(description="faster-whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    parser.add_argument("audio_file", type=str, help="í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model_size", type=str, default="large-v3", help="ì‚¬ìš©í•  Whisper ëª¨ë¸ í¬ê¸° (ì˜ˆ: tiny, base, small, medium, large-v3)")
    parser.add_argument("--device", type=str, default="auto", choices=["auto", "cpu", "cuda"], help="ì‚¬ìš©í•  ì¥ì¹˜ (auto, cpu, cuda)")
    parser.add_argument("--compute_type", type=str, default="default", choices=["default", "int8", "float16"], help="ì—°ì‚° íƒ€ì… (ë©”ëª¨ë¦¬ ë° ì†ë„ ìµœì í™”)")
    parser.add_argument("--language", type=str, default=None, help="ì˜¤ë””ì˜¤ì˜ ì–¸ì–´ ì½”ë“œ (ì˜ˆ: ko, en). ì§€ì • ì‹œ ì–¸ì–´ ê°ì§€ ê³¼ì •ì„ ìƒëµí•˜ì—¬ ë” ë¹ ë¦„.")
    
    args = parser.parse_args([
        "./data/input/quality_test_vocals_clean.wav",
        "--model_size", "base",
        "--device", "cpu",
        "--compute_type", "int8",
    ])

    audio_path = Path(args.audio_file)
    if not audio_path.exists():
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ -> {audio_path}")
        return

    print("="*50)
    print(f"ğŸš€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘: {audio_path.name}")
    print(f"ëª¨ë¸: {args.model_size}, ì¥ì¹˜: {args.device}, ì—°ì‚° íƒ€ì…: {args.compute_type}")
    print("="*50)

    try:
        # ëª¨ë¸ ë¡œë“œ
        model = WhisperModel(args.model_size, device=args.device, compute_type=args.compute_type)
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰
        start_time = time.perf_counter()
        
        segments, info = model.transcribe(str(audio_path), beam_size=5, language=args.language)
        
        # faster-whisperì˜ ê²°ê³¼ëŠ” ì œë„ˆë ˆì´í„°ì´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
        segment_list = list(segments)
        
        end_time = time.perf_counter()
        
        print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")
        print(f"ê°ì§€ëœ ì–¸ì–´: '{info.language}' (í™•ë¥ : {info.language_probability:.2f})")
        
        # ê²°ê³¼ ì €ì¥
        output_basename = audio_path.parent / audio_path.stem # íŒŒì¼ ê²½ë¡œì™€ í™•ì¥ìë¥¼ í•©ì¹˜ëŠ” ì—°ì‚°
        save_as_txt(segment_list, output_basename.with_suffix(".txt"))
        save_as_srt(segment_list, output_basename.with_suffix(".srt"))

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")